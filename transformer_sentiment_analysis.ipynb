{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Downgrade pytorch (please restart runtime after run this cell)\n"
      ],
      "metadata": {
        "id": "sTKh4khyxpun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.9.0\n",
        "!pip install torchtext==0.10.0"
      ],
      "metadata": {
        "id": "eNQAMh1LYYDp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "d23152d4-0eff-4853-c038-6b296fa0858c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 2.6 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0) (4.1.1)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.0+cu113\n",
            "    Uninstalling torch-1.12.0+cu113:\n",
            "      Successfully uninstalled torch-1.12.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.0+cu113 requires torch==1.12.0, but you have torch 1.9.0 which is incompatible.\n",
            "torchtext 0.13.0 requires torch==1.12.0, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 0.12.0+cu113 requires torch==1.12.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.10.0\n",
            "  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 24.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.21.6)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
            "Installing collected packages: torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.0\n",
            "    Uninstalling torchtext-0.13.0:\n",
            "      Successfully uninstalled torchtext-0.13.0\n",
            "Successfully installed torchtext-0.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torchtext"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Definition"
      ],
      "metadata": {
        "id": "f0QFJ6akxuf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math \n",
        "\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ScaledDotProductAttention,self).__init__()\n",
        "        self.softargmax = F.softmax\n",
        "    def forward(self,Q,K,V):\n",
        "        batch_size, head_size, sequnce_length, d_k = K.size()\n",
        "        K_T = K.transpose(2,3)\n",
        "        A = self.softargmax((Q@K_T)/math.sqrt(d_k), dim = -1)\n",
        "        H = A@V\n",
        "        return H\n",
        "\n",
        "class MultiHeadAttention(torch.nn.Module):\n",
        "    def __init__(self,input_dim, head_size,d_model):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        d_q= d_k= d_v = d_model\n",
        "        self.head_size = head_size\n",
        "        self.scaled_dot_product = ScaledDotProductAttention()\n",
        "\n",
        "        self.W_q = nn.Linear(input_dim,head_size*d_q)\n",
        "        self.W_k = nn.Linear(input_dim,head_size*d_k)\n",
        "        self.W_v = nn.Linear(input_dim,head_size*d_v)\n",
        "\n",
        "        self.W_h = nn.Linear(head_size*d_model,d_model)\n",
        "\n",
        "    def split(self,X):\n",
        "        batch_size, sequence_length, num_head_times_d_model = X.size()\n",
        "        d_model = num_head_times_d_model//self.head_size\n",
        "        X = X.view(batch_size, sequence_length, self.head_size,d_model).transpose(1,2)\n",
        "        return X\n",
        "\n",
        "    def concat(self,X):\n",
        "        batch_size, head_size, sequence_length, d_model = X.size()\n",
        "        assert(head_size == self.head_size)\n",
        "        X = X.transpose(1,2).contiguous().view(batch_size, sequence_length,head_size*d_model)\n",
        "        return X\n",
        "\n",
        "    def forward(self,X_query,X_key,X_value):\n",
        "        Q,K,V = self.W_q(X_query), self.W_k(X_key), self.W_v(X_value)\n",
        "        Q,K,V = self.split(Q), self.split(K), self.split(V)\n",
        "        H = self.scaled_dot_product(Q,K,V)\n",
        "        H = self.concat(H)\n",
        "        out = self.W_h(H)\n",
        "        return out"
      ],
      "metadata": {
        "id": "YX-NDjbyMqB1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_hidden, dropout_prob):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.layer1 = nn.Linear(d_model, d_hidden)\n",
        "        self.layer2 = nn.Linear(d_hidden, d_model)\n",
        "        self.dropout = nn.Dropout(p=dropout_prob)\n",
        "        self.relu = nn.ReLU()\n",
        "      \n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.layer2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "QEi6hkj-P-ru"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len, dropout_prob):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout_prob)\n",
        "        position = torch.arange(0, max_len)\n",
        "        position = position.float().unsqueeze(dim=1)\n",
        "        \n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, step=2) * (-math.log(10000.0) / d_model))\n",
        "        \n",
        "        pe[:, 0::2] = torch.sin(position*div_term)\n",
        "        pe[:, 1::2] = torch.cos(position*div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, d_model = x.size()\n",
        "        return self.dropout(self.pe[:seq_len, :].unsqueeze(0)+x)"
      ],
      "metadata": {
        "id": "i23jjceaQIU1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "class EncoderLayer(torch.nn.Module):\n",
        "    def __init__(self,d_model,head_size,mlp_hidden_dim,dropout_prob = 0.1):\n",
        "        super().__init__()\n",
        "        input_dim = d_model\n",
        "        self.attention = MultiHeadAttention(input_dim, head_size, d_model)\n",
        "        self.layer_norm1 = nn.LayerNorm(normalized_shape=d_model, eps=1e-6)\n",
        "        self.layer_norm2 = nn.LayerNorm(normalized_shape=d_model, eps=1e-6)\n",
        "        self.mlp = FeedForward(d_model,mlp_hidden_dim, dropout_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 1. compute self attention\n",
        "        _x = x\n",
        "        x = self.attention(x,x,x)\n",
        "        # 2. add and norm\n",
        "        x = self.layer_norm1(x + _x)\n",
        "        \n",
        "        # 3. positionwise feed forward network\n",
        "        _x = x\n",
        "        x = self.mlp(x)\n",
        "      \n",
        "        # 4. add and norm\n",
        "        x = self.layer_norm2(x + _x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "qpKRqwXTQwP_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Embeddings(nn.Module):\n",
        "    def __init__(self, d_model, vocab_size, max_position_embeddings, p):\n",
        "        super().__init__()\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, d_model, padding_idx=1)\n",
        "        self.positional_encoding = PositionalEncoding( d_model,max_position_embeddings,p)\n",
        "        self.layer_norm = nn.LayerNorm(d_model, eps=1e-12)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        seq_length = input_ids.size(1)\n",
        "        \n",
        "        # Get word embeddings for each input id\n",
        "        word_embeddings = self.word_embeddings(input_ids)                   # (bs, max_seq_length, dim)\n",
        "        \n",
        "        \n",
        "        embeddings = self.positional_encoding(word_embeddings)\n",
        "        # Layer norm \n",
        "        embeddings = self.layer_norm(embeddings)             # (bs, max_seq_length, dim)\n",
        "        return embeddings"
      ],
      "metadata": {
        "id": "tsBXEudGRK08"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, num_layers, d_model, head_size, mlp_hidden_dim, input_vocab_size,\n",
        "               maximum_position_encoding, p=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = Embeddings(d_model, input_vocab_size,maximum_position_encoding, p)\n",
        "\n",
        "        self.enc_layers = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.enc_layers.append(EncoderLayer(d_model, head_size, mlp_hidden_dim, p))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x) # Transform to (batch_size, input_seq_length, d_model)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x)\n",
        "\n",
        "        return x  # (batch_size, input_seq_len, d_model)"
      ],
      "metadata": {
        "id": "MnXd1MrRRZZB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Processing"
      ],
      "metadata": {
        "id": "JmH_7OSAx1VU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext import legacy\n",
        "from torchtext.legacy import data\n",
        "import torchtext.datasets as datasets"
      ],
      "metadata": {
        "id": "GlRiqpTqXuX_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 200\n",
        "text = legacy.data.Field(sequential=True, fix_length=max_len, batch_first=True, lower=True, dtype=torch.long)\n",
        "label = legacy.data.LabelField(sequential=False, dtype=torch.long)\n",
        "ds_train, ds_test = legacy.datasets.IMDB.splits(text, label, root='./')\n",
        "print('train : ', len(ds_train))\n",
        "print('test : ', len(ds_test))\n",
        "print('train.fields :', ds_train.fields)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngU6RVYEhekJ",
        "outputId": "3adda7f6-aaa8-445b-b82b-cc8fdaf00ddf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:08<00:00, 9.95MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train :  25000\n",
            "test :  25000\n",
            "train.fields : {'text': <torchtext.legacy.data.field.Field object at 0x7f685ef928d0>, 'label': <torchtext.legacy.data.field.LabelField object at 0x7f685ef92950>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train, ds_valid = ds_train.split(0.9)\n",
        "print('train : ', len(ds_train))\n",
        "print('valid : ', len(ds_valid))\n",
        "print('test : ', len(ds_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "386qvnk_h5eF",
        "outputId": "121bd14d-ffd3-4a10-d779-516a85a7102e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train :  22500\n",
            "valid :  2500\n",
            "test :  25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_words = 50_000\n",
        "text.build_vocab(ds_train, max_size=num_words)\n",
        "label.build_vocab(ds_train)\n",
        "vocab = text.vocab"
      ],
      "metadata": {
        "id": "ZjOZwi33h_1Q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "batch_size = 164\n",
        "train_loader, valid_loader, test_loader = data.BucketIterator.splits(\n",
        "    (ds_train, ds_valid, ds_test), batch_size=batch_size, sort_key=lambda x: len(x.text), repeat=False)"
      ],
      "metadata": {
        "id": "e4FY4b9QiHR-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerClassifier(nn.Module):\n",
        "    def __init__(self, num_layers, d_model, head_size, conv_hidden_dim, input_vocab_size, num_answers):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = Encoder(num_layers, d_model, head_size, conv_hidden_dim, input_vocab_size,\n",
        "                         maximum_position_encoding=10000)\n",
        "        self.dense = nn.Linear(d_model, num_answers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        \n",
        "        x, _ = torch.max(x, dim=1)\n",
        "        x = self.dense(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "pk-7mE4iiSL2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TransformerClassifier(num_layers=1, d_model=32, head_size=2, \n",
        "                         conv_hidden_dim=128, input_vocab_size=50002, num_answers=2)\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WM3UhVH4ighL",
        "outputId": "51f90e50-1a06-4c6c-8cb2-a221f723e507"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransformerClassifier(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embeddings(\n",
              "      (word_embeddings): Embedding(50002, 32, padding_idx=1)\n",
              "      (positional_encoding): PositionalEncoding(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (layer_norm): LayerNorm((32,), eps=1e-12, elementwise_affine=True)\n",
              "    )\n",
              "    (enc_layers): ModuleList(\n",
              "      (0): EncoderLayer(\n",
              "        (attention): MultiHeadAttention(\n",
              "          (scaled_dot_product): ScaledDotProductAttention()\n",
              "          (W_q): Linear(in_features=32, out_features=64, bias=True)\n",
              "          (W_k): Linear(in_features=32, out_features=64, bias=True)\n",
              "          (W_v): Linear(in_features=32, out_features=64, bias=True)\n",
              "          (W_h): Linear(in_features=64, out_features=32, bias=True)\n",
              "        )\n",
              "        (layer_norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
              "        (layer_norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): FeedForward(\n",
              "          (layer1): Linear(in_features=32, out_features=128, bias=True)\n",
              "          (layer2): Linear(in_features=128, out_features=32, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dense): Linear(in_features=32, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop"
      ],
      "metadata": {
        "id": "2oL8Gf7Rx9_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
        "epochs = 10\n",
        "t_total = len(train_loader) * epochs"
      ],
      "metadata": {
        "id": "0o6FKizlvzj3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, valid_loader):\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        train_iterator, valid_iterator = iter(train_loader), iter(valid_loader)\n",
        "        nb_batches_train = len(train_loader)\n",
        "        train_acc = 0\n",
        "        model.train()\n",
        "        losses = 0.0\n",
        "\n",
        "        for batch in train_iterator:\n",
        "            x = batch.text.cuda()\n",
        "            y = batch.label.cuda()\n",
        "            \n",
        "            out = model(x)  # ①\n",
        "\n",
        "            loss = F.cross_entropy(out, y)  # ②\n",
        "            \n",
        "            model.zero_grad()  # ③\n",
        "\n",
        "            loss.backward()  # ④\n",
        "            losses += loss.item()\n",
        "\n",
        "            optimizer.step()  # ⑤\n",
        "                        \n",
        "            train_acc += (out.argmax(1) == y).cpu().numpy().mean()\n",
        "        \n",
        "        print(f\"Training loss at epoch {epoch} is {losses / nb_batches_train}\")\n",
        "        print(f\"Training accuracy: {train_acc / nb_batches_train}\")\n",
        "        print('Evaluating on validation:')\n",
        "        evaluate(valid_loader)\n",
        "\n"
      ],
      "metadata": {
        "id": "0mkjKGk3w5_o"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(data_loader):\n",
        "    data_iterator = iter(data_loader)\n",
        "    nb_batches = len(data_loader)\n",
        "    model.eval()\n",
        "    acc = 0 \n",
        "    for batch in data_iterator:\n",
        "        x = batch.text.cuda()\n",
        "        y = batch.label.cuda()\n",
        "                \n",
        "        out = model(x)\n",
        "        acc += (out.argmax(1) == y).cpu().numpy().mean()\n",
        "\n",
        "    print(f\"Eval accuracy: {acc / nb_batches}\")"
      ],
      "metadata": {
        "id": "E3vINAtXw-b-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_loader, valid_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VS2run6xNRE",
        "outputId": "e9dfc973-4f38-4729-e0cc-974e6bcca06a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss at epoch 0 is 0.737967532614003\n",
            "Training accuracy: 0.535894971721456\n",
            "Evaluating on validation:\n",
            "Eval accuracy: 0.5721417682926829\n",
            "Training loss at epoch 1 is 0.6543457499448804\n",
            "Training accuracy: 0.6233927624602336\n",
            "Evaluating on validation:\n",
            "Eval accuracy: 0.6350990853658536\n",
            "Training loss at epoch 2 is 0.5996039017387058\n",
            "Training accuracy: 0.6872459349593496\n",
            "Evaluating on validation:\n",
            "Eval accuracy: 0.7\n",
            "Training loss at epoch 3 is 0.5204477003519086\n",
            "Training accuracy: 0.7426431601272536\n",
            "Evaluating on validation:\n",
            "Eval accuracy: 0.7453887195121952\n",
            "Training loss at epoch 4 is 0.4486882384272589\n",
            "Training accuracy: 0.79110330505479\n",
            "Evaluating on validation:\n",
            "Eval accuracy: 0.791158536585366\n",
            "Training loss at epoch 5 is 0.3915546417668246\n",
            "Training accuracy: 0.8251977288794629\n",
            "Evaluating on validation:\n",
            "Eval accuracy: 0.8052591463414634\n",
            "Training loss at epoch 6 is 0.3570093303055003\n",
            "Training accuracy: 0.8435677359490986\n",
            "Evaluating on validation:\n",
            "Eval accuracy: 0.8117378048780487\n",
            "Training loss at epoch 7 is 0.3198191075437311\n",
            "Training accuracy: 0.8652626811594198\n",
            "Evaluating on validation:\n",
            "Eval accuracy: 0.8174923780487806\n",
            "Training loss at epoch 8 is 0.28840182937573694\n",
            "Training accuracy: 0.8790153322728882\n",
            "Evaluating on validation:\n",
            "Eval accuracy: 0.8198170731707318\n",
            "Training loss at epoch 9 is 0.25747537882863614\n",
            "Training accuracy: 0.8945906238953694\n",
            "Evaluating on validation:\n",
            "Eval accuracy: 0.8144054878048781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkYHoRjzxZQ1",
        "outputId": "26e0574c-c90a-4fad-bd11-273d4c375b6e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval accuracy: 0.8081216678179853\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "transformer_sentiment_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "sTKh4khyxpun",
        "f0QFJ6akxuf2",
        "JmH_7OSAx1VU",
        "2oL8Gf7Rx9_m"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}